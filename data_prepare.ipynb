{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "eeb3fcaf-1c57-4955-b23d-3902df6f5d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import datetime\n",
    "import collections\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d68939f4-ea47-43d6-94c8-a07fa66eebfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def processing_mimic3(file_adm, file_dxx, output_file):\n",
    "\n",
    "    m_adm = pd.read_csv(file_adm, dtype={'HOSPITAL_EXPIRE_FLAG': object})\n",
    "    m_dxx = pd.read_csv(file_dxx, dtype={'ICD9_CODE': object})\n",
    "\n",
    "    # get total unique patients\n",
    "    unique_pats = m_dxx.SUBJECT_ID.unique()\n",
    "\n",
    "    patients = []  # store all preprocessed patients' data\n",
    "    for sub_id in unique_pats:\n",
    "        patient = dict()\n",
    "        patient['pid'] = str(sub_id)\n",
    "        pat_dxx = m_dxx[m_dxx.SUBJECT_ID == sub_id]  # get a specific patient's all data in dxx file\n",
    "        uni_hadm = pat_dxx.HADM_ID.unique()  # get all unique admissions\n",
    "        grouped = pat_dxx.groupby(['HADM_ID'])\n",
    "        visits = []\n",
    "        for hadm in uni_hadm:\n",
    "            act = dict()\n",
    "            adm = m_adm[(m_adm.SUBJECT_ID == sub_id) & (m_adm.HADM_ID == hadm)]\n",
    "            admsn_dt = datetime.datetime.strptime(adm.ADMITTIME.values[0], \"%Y-%m-%d %H:%M:%S\")\n",
    "            disch_dt = datetime.datetime.strptime(adm.DISCHTIME.values[0], \"%Y-%m-%d %H:%M:%S\")\n",
    "            death_flag = adm.HOSPITAL_EXPIRE_FLAG.values[0]\n",
    "\n",
    "            delta = disch_dt - admsn_dt\n",
    "            act['admsn_dt'] = admsn_dt.strftime(\"%Y%m%d\")\n",
    "            act['day_cnt'] = str(delta.days + 1)\n",
    "\n",
    "            codes = grouped.get_group(hadm)  # get all diagnosis codes in the adm\n",
    "            DXs = []\n",
    "            for index, row in codes.iterrows():\n",
    "                dx = row['ICD9_CODE']\n",
    "                # if dx is not NaN\n",
    "                if dx == dx:\n",
    "                    DXs.append(dx)\n",
    "\n",
    "            act['DXs'] = DXs\n",
    "            act['Death'] = death_flag\n",
    "            visits.append(act)\n",
    "        #print('patient {} is processed!'.format(sub_id))\n",
    "        patient['visits'] = visits\n",
    "        patients.append(patient)\n",
    "\n",
    "    with open(output_file, 'w') as outfile:\n",
    "        json.dump(patients, outfile)\n",
    "\n",
    "    return patients\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8817a921-2466-46fc-beb4-2cbff509e129",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_clip(patients_full, visit_threshold, code_min_freq, output_file):\n",
    "    patients = [patient for patient in patients_full if len(patient['visits']) >= visit_threshold]\n",
    "    \n",
    "    all_codes = []\n",
    "    total_visits = 0\n",
    "    \n",
    "    for patient in patients:\n",
    "        for visit in patient['visits']:\n",
    "            total_visits += 1\n",
    "            dxs = visit['DXs']\n",
    "            for dx in dxs:\n",
    "                all_codes.append(dx)\n",
    "    \n",
    "    count_org = []\n",
    "    count_org.extend(collections.Counter(all_codes).most_common())\n",
    "    \n",
    "    count = []\n",
    "    words_count = 0\n",
    "    for word, c in count_org:\n",
    "        word_tuple = [word, c]\n",
    "        if c >= code_min_freq:\n",
    "            count.append(word_tuple)\n",
    "            words_count += c\n",
    "    \n",
    "    code_no_per_visit = words_count / total_visits\n",
    "    print(\"visits per patient: {}\".format(total_visits/len(patients)))\n",
    "    print(\"diagnosis code per visit: {}\".format(code_no_per_visit))\n",
    "    \n",
    "    code_dictionary = {}\n",
    "    code_dictionary['PAD'] = 0\n",
    "    for word, cnt in count:\n",
    "        index = len(code_dictionary)\n",
    "        code_dictionary[word] = index\n",
    "    \n",
    "    max_visits = 0\n",
    "    max_len_visit = 0\n",
    "    \n",
    "    for p in patients:\n",
    "        visits = p['visits']\n",
    "        len_visits = len(visits)\n",
    "        if len_visits > max_visits:\n",
    "            max_visits = len_visits        \n",
    "        for visit in visits:\n",
    "            dxs = visit['DXs']\n",
    "            if len(dxs) == 0:\n",
    "                continue\n",
    "            else:\n",
    "                visit['DXs'] = [code_dictionary[dx] for dx in dxs if dx in code_dictionary]\n",
    "            len_current_visit = len(visit['DXs'])   \n",
    "            if len_current_visit > max_len_visit:\n",
    "                max_len_visit = len_current_visit\n",
    "            \n",
    "    with open(output_file, 'w') as fp:\n",
    "        json.dump(patients, fp)\n",
    "    return patients, max_visits, max_len_visit, code_dictionary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c7bc3a33-9e20-42b4-89da-911d3bfa8cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_process(patients, valid_visits_threshold, max_len_visit, code_dictionary, output_file):\n",
    "    batches = []\n",
    "    n_zeros = 0\n",
    "    for patient in patients:\n",
    "        pid = patient['pid']\n",
    "        # get patient's visits\n",
    "        visits = patient['visits']\n",
    "        # sorting visits by admission date\n",
    "        sorted_visits = sorted(visits, key=lambda visit: visit['admsn_dt'])\n",
    "        valid_visits = []\n",
    "        for v in sorted_visits:\n",
    "            if len(v['DXs']) > 0 and sum(v['DXs']) > 0:\n",
    "                valid_visits.append(v)\n",
    "\n",
    "        if (len(valid_visits)) < 2:\n",
    "            continue    \n",
    "            \n",
    "        # number of visits and only use 10 visits to predict last one if number of visits is larger than 11\n",
    "        no_visits = len(valid_visits)\n",
    "        last_visit = valid_visits[no_visits - 1]\n",
    "        second_last_visit = valid_visits[no_visits - 2]\n",
    "\n",
    "        ls_codes = []\n",
    "        ls_intervals = []\n",
    "        # only use 10 visits to predict last one if number of visits is larger than 11\n",
    "        if no_visits > valid_visits_threshold+1:\n",
    "            feature_visits = valid_visits[no_visits-(valid_visits_threshold+1):no_visits-1]\n",
    "        else:\n",
    "            feature_visits = valid_visits[0:no_visits - 1]\n",
    "\n",
    "        n_visits = len(feature_visits)\n",
    "\n",
    "        \n",
    "        first_valid_visit_dt = datetime.datetime.strptime(feature_visits[0]['admsn_dt'], \"%Y%m%d\")\n",
    "        for i in range(n_visits):\n",
    "            visit = feature_visits[i]\n",
    "            codes = visit['DXs']\n",
    "\n",
    "            if sum(codes) == 0:\n",
    "                n_zeros += 1\n",
    "\n",
    "            current_dt = datetime.datetime.strptime(visit['admsn_dt'], \"%Y%m%d\")\n",
    "            interval = (current_dt - first_valid_visit_dt).days + 1\n",
    "            ls_intervals.append(interval)\n",
    "            code_size = len(codes)\n",
    "            # code padding\n",
    "            if code_size < max_len_visit:\n",
    "                list_zeros = [0] * (max_len_visit - code_size)\n",
    "                codes.extend(list_zeros)\n",
    "            ls_codes.append(codes)\n",
    "\n",
    "        # visit padding\n",
    "        if n_visits < valid_visits_threshold:\n",
    "            for i in range(valid_visits_threshold - n_visits):\n",
    "                list_zeros = [0] * max_len_visit\n",
    "                ls_codes.append(list_zeros)\n",
    "                ls_intervals.append(0)\n",
    "\n",
    "\n",
    "        last_dt = datetime.datetime.strptime(last_visit['admsn_dt'], \"%Y%m%d\")\n",
    "        second_last_dt = datetime.datetime.strptime(second_last_visit['admsn_dt'], \"%Y%m%d\")\n",
    "        days = (last_dt - second_last_dt).days\n",
    "        if days <= 30:\n",
    "            adm_label = 1\n",
    "        else:\n",
    "            adm_label = 0\n",
    "        # --------- end readmission label --------------------     \n",
    "        \n",
    "        one_hot_labels = np.zeros(len(code_dictionary)).astype(int)\n",
    "        last_codes = last_visit['DXs']\n",
    "        for code in last_codes:\n",
    "            index = code\n",
    "            one_hot_labels[index] = 1\n",
    "        \n",
    "        batches.append(\n",
    "                [np.array(ls_codes, dtype=np.int32), one_hot_labels, np.array([adm_label], dtype=np.int32), pid,\n",
    "                 np.array(ls_intervals, dtype=np.int32)])\n",
    "\n",
    "    codes = []\n",
    "    dx_labels = []\n",
    "    re_labels = []\n",
    "    pids = []\n",
    "    intervals = []\n",
    "    for batch in batches:\n",
    "        codes.append(batch[0])\n",
    "        dx_labels.append(batch[1])\n",
    "        re_labels.append(batch[2])\n",
    "        pids.append(batch[3])\n",
    "        intervals.append(batch[4])\n",
    "\n",
    "    data = [codes, dx_labels, re_labels, pids, intervals]\n",
    "    \n",
    "    \n",
    "    \n",
    "    context_codes = data[0]\n",
    "    labels_1 = data[1]\n",
    "    labels_2 = data[2]\n",
    "    pids = data[3]\n",
    "    intervals = data[4]\n",
    "\n",
    "    context_codes = np.array(context_codes, dtype=np.int32)\n",
    "    intervals = np.array(intervals, dtype=np.int32)\n",
    "    labels_1 = np.array(labels_1, dtype=np.int32)\n",
    "    labels_2 = np.array(labels_2, dtype=np.int32)\n",
    "    pids = np.array(pids, dtype=np.int32)\n",
    "\n",
    "    train_context_codes, vt_context_codes, train_labels_1, vt_labels_1, \\\n",
    "    train_labels_2, vt_labels_2, train_pids, vt_pids, train_intervals, vt_intervals\\\n",
    "        = train_test_split(context_codes, labels_1, labels_2, pids, intervals, test_size=0.2, random_state=42)\n",
    "\n",
    "    train_size = len(train_context_codes)\n",
    "\n",
    "    dev_context_codes, test_context_codes, dev_labels_1, test_labels_1, dev_labels_2, \\\n",
    "    test_labels_2, dev_pids, test_pids, dev_intervals, test_intervals \\\n",
    "        = train_test_split(vt_context_codes, vt_labels_1, vt_labels_2, vt_pids,vt_intervals,\n",
    "                           test_size=0.5, random_state=42)\n",
    "    \n",
    "    train = {\"context_codes\": train_context_codes.tolist(), \"labels_1\": train_labels_1.tolist(), \"labels_2\": train_labels_2.tolist(), \"pids\": train_pids.tolist(), \"intervals\": train_intervals.tolist()}\n",
    "    dev = {\"context_codes\": dev_context_codes.tolist(), \"labels_1\": dev_labels_1.tolist(), \"labels_2\": dev_labels_2.tolist(), \"pids\": dev_pids.tolist(), \"intervals\": dev_intervals.tolist()}\n",
    "    test = {\"context_codes\": test_context_codes.tolist(), \"labels_1\": test_labels_1.tolist(), \"labels_2\": test_labels_2.tolist(), \"pids\": test_pids.tolist(), \"intervals\": test_intervals.tolist()}\n",
    "    \n",
    "    #print(type(train[\"context_codes\"]))\n",
    "    \n",
    "    with open(output_file + 'train.json', 'w') as fp:\n",
    "        json.dump(train, fp)\n",
    "    with open(output_file + 'dev.json', 'w') as fp:\n",
    "        json.dump(dev, fp)\n",
    "    with open(output_file + 'test.json', 'w') as fp:\n",
    "        json.dump(test, fp)\n",
    "        \n",
    "    return train,dev,test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3cedcc85-4c4a-4ccf-8356-a265467b38b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_adm = './data/ADMISSIONS.csv'\n",
    "file_dxx = './data/DIAGNOSES_ICD.csv'\n",
    "output_file = './data/patients_mimic3_dx.json'\n",
    "\n",
    "patients_full = processing_mimic3(file_adm, file_dxx, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7f4ada8f-5c2c-4765-ad0d-c4af160aa6fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46520"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(patients_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3f0a380f-4c2e-47f9-bb9f-7870a393dd1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "visits per patient: 2.6526469417540137\n",
      "diagnosis code per visit: 12.794127944780673\n"
     ]
    }
   ],
   "source": [
    "visit_threshold = 2\n",
    "code_min_freq = 5\n",
    "output_file = './data/patients_mimic3_dx_clip.json'\n",
    "patients, max_visits, max_len_visit, code_dictionary = data_clip(patients_full, visit_threshold, code_min_freq, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7953ebd8-c17b-46fc-8ae6-6464b46e4fed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7537"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(patients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "8bd50440-8c01-4a8f-83f7-a5e38c00ba01",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = './data/'\n",
    "valid_visits_threshold = 10\n",
    "train, dev, test = data_process(patients, valid_visits_threshold, max_len_visit, code_dictionary, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ea3b8a08-ce44-4db0-bcbe-9d920896ae13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42 39\n"
     ]
    }
   ],
   "source": [
    "print(max_visits, max_len_visit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "4b81a85b-3932-4c35-97c1-9ece5bebcc96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train[\"context_codes\"][5][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "b2cc13ad-e9cb-4067-96a4-102029c67465",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2438"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(code_dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "d5708eae-a390-4863-aa2b-b661b3ec0f05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5992"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train[\"context_codes\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "956a99c6-0030-4df4-bd04-bb7ff492f4ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
