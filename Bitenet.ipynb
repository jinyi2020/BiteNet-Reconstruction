{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c8ff1cfe-ace6-4e30-b86e-9382177ce630",
   "metadata": {},
   "source": [
    "# BiteNet reproduction\n",
    "\n",
    "When using RNN on BiteNet, the forgetfulness of RNN tends to lose memory of long term data.\n",
    "\n",
    "Attention mechanism have some good performance, but not quite fit for EHR data, as for timestamps and hierarchical data.\n",
    "\n",
    "BiteNet claims to have longer memory and have improvements on timestamps and hierarchical data\n",
    "\n",
    "The project reproduce BiteNet model. Use MIMIC III data as input. With diagnosis codes and time stamp of each visit, predict re-admission.\n",
    "Also predict with baseline models RNN and RETAIN.\n",
    "\n",
    "Result shows that BiteNet performs better than baseline modes.\n",
    "AUC score of this project is not exactly same as original paper. This could be from some parameters are not specified in original paper. \n",
    "So settings here is not same as original paper.\n",
    "\n",
    "BiteNet paper: Xueping Peng, Guodong Long, Tao Shen, Sen Wang, Jing Jiang, and Chengqi Zhang. 2020. Bitenet: bidirectional temporal encoder network to predict medical outcomes. In 2020 IEEE International Conference on Data Mining (ICDM), pages 412â€“421. IEEE."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2640ec28-a489-4459-bfd4-ea2c1f94bb4b",
   "metadata": {},
   "source": [
    "## Part 1: Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6bfca096-c7b9-4352-8de3-903acfa2705f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6b4ee8e-b039-4289-a32e-6fbcf106b3d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/train.json', 'r') as f:\n",
    "    train = json.load(f)\n",
    "with open('./data/dev.json', 'r') as f:\n",
    "    val = json.load(f)\n",
    "with open('./data/test.json', 'r') as f:\n",
    "    test = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f39f3c1-7efe-49fd-96fa-eb0856168eae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "749\n",
      "5992\n"
     ]
    }
   ],
   "source": [
    "print(len(test['context_codes']))\n",
    "print(len(train['context_codes']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "617fd9a4-57e3-4c5d-93c6-59cb4554fd85",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.keys()\n",
    "train_small_size = 640\n",
    "train_small = {}\n",
    "test_small = {}\n",
    "for k in train:\n",
    "    train_small[k] = train[k][:int(len(train['context_codes'])/32)*32]\n",
    "    test_small[k] = test[k][:int(len(test['context_codes'])/32)*32]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "17807ccb-c76c-47bc-a611-4e5a5e670e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, seqs, time, label):\n",
    "        self.x = torch.tensor(seqs)\n",
    "        self.t = torch.tensor(time)\n",
    "        self.y = torch.tensor(label)\n",
    "    \n",
    "    def __len__(self):\n",
    "        \n",
    "        \n",
    "        return len(self.x)\n",
    "        \n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        \n",
    "        return self.x[index], self.t[index], self.y[index]\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fc8946d2-97d0-418c-ba33-a0cb16eb6a9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"train_dataset = CustomDataset(train['context_codes'], train['intervals'], train['labels_2'])\\nval_dataset = CustomDataset(val['context_codes'], val['intervals'], val['labels_2'])\\ntest_dataset = CustomDataset(test['context_codes'], test['intervals'], test['labels_2'])\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset = CustomDataset(train_small['context_codes'], train_small['intervals'], train_small['labels_2'])\n",
    "val_dataset = CustomDataset(val['context_codes'], val['intervals'], val['labels_2'])\n",
    "test_dataset = CustomDataset(test_small['context_codes'], test_small['intervals'], test_small['labels_2'])\n",
    "\n",
    "'''train_dataset = CustomDataset(train['context_codes'], train['intervals'], train['labels_2'])\n",
    "val_dataset = CustomDataset(val['context_codes'], val['intervals'], val['labels_2'])\n",
    "test_dataset = CustomDataset(test['context_codes'], test['intervals'], test['labels_2'])'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5ca0ccb7-89c3-44db-b0eb-be2a10761720",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def load_data(train_dataset, val_dataset, test_dataset):\n",
    "    \n",
    "    batch_size = 32\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    return train_loader, val_loader, test_loader\n",
    "\n",
    "\n",
    "train_loader, val_loader, test_loader = load_data(train_dataset, val_dataset, test_dataset)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b10b4b0-da78-4745-9084-c5e5e5135074",
   "metadata": {},
   "source": [
    "## Part 2: BiteNet construction\n",
    "\n",
    "The MasEnc block is constructed in EncoderStack.\n",
    "\n",
    "BiteNet put inputs of codes through embedding, MasEnc block, then attention pooling. Input of time interval goes through embedding.\n",
    "Add results together and goes through two MasEnc separately with different mask. Do attention pool again. Concat results and feed foward to output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "519dff11-bdb4-4157-b7c0-a1a1b0361820",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualConnection(torch.nn.Module):\n",
    "    def __init__(self, layer, input_dim):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.layer = layer\n",
    "        self.layer_norm = nn.LayerNorm(input_dim)\n",
    "    \n",
    "    def forward(self, x, mask):\n",
    "        #print(\"x shape: \", x.shape)\n",
    "        y = self.layer_norm(x)\n",
    "        #print(\"y shape: \", y.shape)\n",
    "        y = self.layer(y, mask)\n",
    "        #print(self.layer)\n",
    "        #print(\"y shape: \", y.shape)\n",
    "        return x + y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fb8cafed-e60b-4f15-9055-ae848d03f0f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MasEnc(torch.nn.Module):\n",
    "    def __init__(self, input_dim, embed_dim, num_heads, attn_mask):\n",
    "        super().__init__()\n",
    "\n",
    "        self.embed_dim = embed_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.atten_mask = attn_mask\n",
    "\n",
    "        \n",
    "        self.q_linear = nn.Linear(input_dim, embed_dim, bias = False)\n",
    "        self.k_linear = nn.Linear(input_dim, embed_dim, bias = False)\n",
    "        self.v_linear = nn.Linear(input_dim, embed_dim, bias = False)\n",
    "        \n",
    "        self.mulatt = nn.MultiheadAttention(embed_dim = self.embed_dim, num_heads = self.num_heads, batch_first = True)\n",
    "        \n",
    "    \n",
    "    def forward(self, x, input_mask):\n",
    "        queries = x\n",
    "        keys = x\n",
    "        \n",
    "        q = self.q_linear(queries)  # (N, L_q, d)\n",
    "        k = self.k_linear(keys)  # (N, L_k, d)\n",
    "        v = self.v_linear(keys)  # (N, L_k, d)\n",
    "        \n",
    "        if self.atten_mask == 'diag':\n",
    "            attn_mask = torch.diag(torch.ones(x.shape[1]).bool())\n",
    "        elif self.atten_mask == 'forward':\n",
    "            attn_mask = torch.triu(torch.ones(x.shape[1], x.shape[1], dtype=torch.bool), diagonal=1)\n",
    "        elif self.atten_mask == 'backward':\n",
    "            attn_mask = torch.tril(torch.ones(x.shape[1], x.shape[1], dtype=torch.bool), diagonal=-1)\n",
    "        else:\n",
    "            attn_mask = torch.zeros(x.shape[1], x.shape[1], dtype=torch.bool)\n",
    "              \n",
    "        \n",
    "        #data = self.mulatt(q, k, v, key_padding_mask = ~input_mask, attn_mask = attn_mask, need_weights = False)\n",
    "        data = self.mulatt(q, k, v, attn_mask = attn_mask, need_weights = False)\n",
    "        '''print(\"MasEnc q: \", q.shape, q.min(), q.max())\n",
    "        print(\"MasEnc k: \", k.shape, k.min(), k.max())\n",
    "        print(\"MasEnc v: \", v.shape, v.min(), v.max())\n",
    "        print(\"MasEnc im: \", input_mask.shape, input_mask.min(), input_mask.max())\n",
    "        print(\"MasEnc m: \", attn_mask.shape, attn_mask.min(), attn_mask.max(), attn_mask)\n",
    "        print(\"MasEnc out: \", data[0].shape, data[0].min(), data[0].max())'''\n",
    "        #print(\"call masenc\")\n",
    "        #print(\"masenc out shape: \", len(data), data[0].shape, data[1].shape)\n",
    "        \n",
    "        return data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3a834c42-6da3-48a9-a8aa-43577f82088b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForwardNetwork(torch.nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, filter_size, dropout):\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.filter_size = filter_size\n",
    "        self.dropout = dropout\n",
    "        \n",
    "        self.filter_layer = nn.Linear(input_size, filter_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.drop_layer = nn.Dropout(dropout)\n",
    "        self.output_layer = nn.Linear(filter_size, hidden_size)\n",
    "        \n",
    "    def forward(self, x, input_size):\n",
    "        out = self.filter_layer(x)\n",
    "        #print(\"FFN0: \", out.shape, out.min(), out.max())\n",
    "        out = self.relu(out)\n",
    "        #print(\"FFN1: \", out.shape, out.min(), out.max())\n",
    "        out = self.drop_layer(out)\n",
    "        #print(\"FFN2: \", out.shape, out.min(), out.max())\n",
    "        out = self.output_layer(out)\n",
    "        #print(\"FFN3: \", out.shape, out.min(), out.max())\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1fac0376-960a-493b-8f9e-b0f2e99b6ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderStack(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, input_dim, embed_dim, num_heads, attn_mask, n_hidden_layers, n_batch, n_visit, hidden_size, filter_size, dropout):\n",
    "        super().__init__()\n",
    "        self.embed_dim = embed_dim\n",
    "        self.output_normalization = nn.LayerNorm([n_batch, n_visit, embed_dim])\n",
    "        self.layers = []\n",
    "        \n",
    "        for i in range(n_hidden_layers):\n",
    "            masked_encoder_layer = MasEnc(input_dim, embed_dim, num_heads, attn_mask)\n",
    "            feed_forward_network = FeedForwardNetwork(embed_dim, hidden_size, filter_size, dropout)\n",
    "            \n",
    "            self.layers.append([\n",
    "                                ResidualConnection(masked_encoder_layer, [n_batch, n_visit, embed_dim]), \n",
    "                                ResidualConnection(feed_forward_network, [n_batch, n_visit, embed_dim])\n",
    "                                ])\n",
    "            \n",
    "\n",
    "    def forward(self, x, input_mask):\n",
    "        \n",
    "        for layer in self.layers:\n",
    "            masked_encoder_layer = layer[0]\n",
    "            feed_forward_network = layer[1]\n",
    "            \n",
    "            #print(\"EncoderStack0: \", x.shape, x.min(), x.max())\n",
    "            x = masked_encoder_layer(x, input_mask)\n",
    "            #print(\"EncoderStack1: \", x.shape, x.min(), x.max())\n",
    "            x = feed_forward_network(x, input_mask)\n",
    "            #print(\"EncoderStack2: \", x.shape, x.min(), x.max())\n",
    "        \n",
    "        out = self.output_normalization(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "528a9d94-ddc8-414b-b90f-652716c95491",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionPooling(torch.nn.Module):\n",
    "    def __init__(self, embedding_size):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.fc1 = nn.Linear(embedding_size, embedding_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(embedding_size, embedding_size)\n",
    "        \n",
    "    def forward(self,x, input_mask):\n",
    "        #print(\"AttentionPooling0: \", x.shape, x.min(), x.max())\n",
    "        x = self.fc2(self.relu(self.fc1(x)))\n",
    "        #print(\"AttentionPooling1: \", x.shape, x.min(), x.max())\n",
    "        _mask = torch.zeros_like(input_mask)\n",
    "        _mask[~input_mask] = float('-inf')\n",
    "        x = x + _mask.unsqueeze(-1)\n",
    "        #print(\"AttentionPooling2: \", x.shape, x.min(), x.max())\n",
    "        soft = torch.nn.functional.softmax(x,1)\n",
    "        #print(\"AttentionPooling3: \", soft.shape, soft.min(), soft.max())\n",
    "        out = (soft*x).sum(dim = 1)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "12e59485-a306-49ce-8195-89068b6ec1ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiteNet(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.lr = 0.0001\n",
    "        self.dropout_rate = 0.1\n",
    "        self.n_intervals = 12 * 365 + 1\n",
    "        self.n_visits = 10\n",
    "        self.n_codes = 39\n",
    "        self.vocabulary_size = 2438\n",
    "        self.digit3_size = 2438\n",
    "        self.pos_encoding = None\n",
    "        self.embedding_size = 50\n",
    "        self.num_hidden_layers = 2\n",
    "        self.num_heads = 2\n",
    "        self.batch = 32\n",
    "        \n",
    "        self.hidden_size = self.embedding_size\n",
    "        self.filter_size = self.embedding_size\n",
    "        \n",
    "        self.code_embedding_layer = torch.nn.Embedding(self.vocabulary_size, self.embedding_size) \n",
    "        self.interval_embedding_layer = torch.nn.Embedding(self.n_intervals, self.embedding_size) \n",
    "        self.common_layer1 = EncoderStack(self.embedding_size, self.embedding_size, self.num_heads, 'diag', \n",
    "                                          self.num_hidden_layers, self.batch * self.n_visits, self.n_codes, \n",
    "                                          self.hidden_size, self.filter_size, self.dropout_rate)\n",
    "        self.attn_pool_layer1 = AttentionPooling(self.embedding_size)\n",
    "        self.common_layer2 = EncoderStack(self.embedding_size, self.embedding_size, self.num_heads, 'forward', \n",
    "                                          self.num_hidden_layers, self.batch, self.n_visits, \n",
    "                                          self.hidden_size, self.filter_size, self.dropout_rate)\n",
    "        self.common_layer3 = EncoderStack(self.embedding_size, self.embedding_size, self.num_heads, 'backward', \n",
    "                                          self.num_hidden_layers, self.batch, self.n_visits, \n",
    "                                          self.hidden_size, self.filter_size, self.dropout_rate)\n",
    "        self.attn_pool_layer2 = AttentionPooling(self.embedding_size)\n",
    "        self.attn_pool_layer3 = AttentionPooling(self.embedding_size)\n",
    "        self.fc1 = nn.Linear(2*self.embedding_size, 2*self.embedding_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(self.dropout_rate)\n",
    "        self.fc2 = nn.Linear(2*self.embedding_size,1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    def forward(self, code_input, interval_input):\n",
    "        inputs_mask = (code_input != 0)\n",
    "        visit_mask = (code_input.sum(-1) != 0)\n",
    "        \n",
    "        # shape [batch_size, n_visits, n_codes, embedding_size]\n",
    "        code_embed = self.code_embedding_layer(code_input)\n",
    "        # reshape to (batch*n_visit, n_codes, embedding_size)\n",
    "        e = code_embed.reshape(code_embed.shape[0]*code_embed.shape[1],code_embed.shape[2],code_embed.shape[3])\n",
    "        \n",
    "        #print(\"e: \", e.shape, e.min(), e.max())\n",
    "        # reshape to (batch*n_visit, n_codes)\n",
    "        e_mask = inputs_mask.reshape(inputs_mask.shape[0]*inputs_mask.shape[1],inputs_mask.shape[2])\n",
    "        \n",
    "        h = self.common_layer1(e, e_mask)\n",
    "        \n",
    "        #print(\"h: \", h.shape, h.min(), h.max())\n",
    "        \n",
    "        v = self.attn_pool_layer1(h, e_mask)\n",
    "        #print(\"v: \", v.shape, v.min(), v.max())\n",
    "        \n",
    "        # reshape to (batch, n_visit, embedding_size)\n",
    "        v = v.reshape(code_input.shape[0],code_input.shape[1],self.embedding_size)\n",
    "        \n",
    "        e_p = self.interval_embedding_layer(interval_input)\n",
    "        \n",
    "        \n",
    "        v = v + e_p\n",
    "        #print(\"v: \", v.shape, v.min(), v.max())\n",
    "        \n",
    "        \n",
    "        o_fw = self.common_layer2(v, visit_mask)\n",
    "        #print(\"o_fw: \", o_fw.shape, o_fw.min(), o_fw.max())\n",
    "        u_fw = self.attn_pool_layer2(o_fw, visit_mask)\n",
    "        #print(\"u_fw: \", u_fw.shape, u_fw.min(), u_fw.max())\n",
    "        o_bw = self.common_layer3(v, visit_mask)\n",
    "        #print(\"o_bw: \", o_bw.shape, o_bw.min(), o_bw.max())\n",
    "        u_bw = self.attn_pool_layer3(o_bw, visit_mask)\n",
    "        #print(\"u_bw: \", u_bw.shape, u_bw.min(), u_bw.max())\n",
    "        \n",
    "        b_bi = torch.cat((u_fw, u_bw), 1)\n",
    "        #print(\"b_bi: \", b_bi.shape, b_bi.min(), b_bi.max())\n",
    "        out = self.sigmoid(self.fc2(self.dropout(self.relu(self.fc1(b_bi)))))\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "658aa312-22fd-4c44-8e04-f34d309e83ce",
   "metadata": {},
   "source": [
    "## Part 3: Test for BiteNet\n",
    "\n",
    "run for 10 rounds. Each round has 10 epochs. Record last epoch auc score.\n",
    "Take average of 10 rounds for final result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bfca253d-d88a-4e52-80f0-a5ff10db2653",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1678451"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bitenet = BiteNet()\n",
    "count_para = sum(p.numel() for p in bitenet.parameters() if p.requires_grad)\n",
    "count_para"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "35e95be2-9bf2-4ddc-8604-846f3b866ccb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jinyi/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jinyi/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Train Score: 0.2207, 0.0000, Test Score: 0.1766, 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jinyi/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jinyi/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 002, Train Score: 0.2331, 0.0000, Test Score: 0.1794, 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jinyi/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jinyi/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 003, Train Score: 0.2472, 0.0000, Test Score: 0.1785, 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jinyi/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jinyi/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 004, Train Score: 0.2764, 0.0000, Test Score: 0.1854, 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jinyi/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 005, Train Score: 0.3201, 1.0000, Test Score: 0.2068, 0.0000\n",
      "Epoch: 006, Train Score: 0.3251, 1.0000, Test Score: 0.2302, 0.0000\n",
      "Epoch: 007, Train Score: 0.3782, 0.9697, Test Score: 0.2105, 0.3333\n",
      "Epoch: 008, Train Score: 0.5010, 0.9096, Test Score: 0.3107, 0.6667\n",
      "Epoch: 009, Train Score: 0.5516, 0.6054, Test Score: 0.3093, 0.3059\n",
      "Epoch: 010, Train Score: 0.6000, 0.8514, Test Score: 0.2701, 0.4250\n",
      "round 1, auc 0.27009182567630896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jinyi/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jinyi/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Train Score: 0.2237, 0.0000, Test Score: 0.1798, 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jinyi/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jinyi/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 002, Train Score: 0.2302, 0.0000, Test Score: 0.1779, 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jinyi/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jinyi/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 003, Train Score: 0.2689, 0.0000, Test Score: 0.1891, 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jinyi/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jinyi/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 004, Train Score: 0.3000, 0.0000, Test Score: 0.1938, 0.0000\n",
      "Epoch: 005, Train Score: 0.4346, 0.9487, Test Score: 0.2952, 1.0000\n",
      "Epoch: 006, Train Score: 0.4872, 0.8564, Test Score: 0.2900, 0.8333\n",
      "Epoch: 007, Train Score: 0.5489, 0.8176, Test Score: 0.2946, 0.4500\n",
      "Epoch: 008, Train Score: 0.5868, 0.7875, Test Score: 0.2923, 0.3469\n",
      "Epoch: 009, Train Score: 0.6185, 0.8225, Test Score: 0.3119, 0.4571\n",
      "Epoch: 010, Train Score: 0.6534, 0.8267, Test Score: 0.2777, 0.3091\n",
      "round 2, auc 0.27765832230032417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jinyi/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jinyi/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Train Score: 0.2255, 0.0000, Test Score: 0.1841, 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jinyi/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jinyi/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 002, Train Score: 0.2304, 0.0000, Test Score: 0.1810, 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jinyi/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jinyi/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 003, Train Score: 0.2509, 0.0000, Test Score: 0.1849, 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jinyi/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jinyi/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 004, Train Score: 0.3100, 0.0000, Test Score: 0.1855, 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jinyi/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 005, Train Score: 0.3339, 1.0000, Test Score: 0.1804, 0.0000\n",
      "Epoch: 006, Train Score: 0.4380, 0.9487, Test Score: 0.2269, 0.5000\n",
      "Epoch: 007, Train Score: 0.5294, 0.9186, Test Score: 0.2799, 0.7143\n",
      "Epoch: 008, Train Score: 0.5626, 0.8109, Test Score: 0.2862, 0.4333\n",
      "Epoch: 009, Train Score: 0.6126, 0.8337, Test Score: 0.2609, 0.4103\n",
      "Epoch: 010, Train Score: 0.6420, 0.6948, Test Score: 0.2591, 0.2958\n",
      "round 3, auc 0.25914291330787853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jinyi/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jinyi/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Train Score: 0.2229, 0.0000, Test Score: 0.1902, 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jinyi/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jinyi/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 002, Train Score: 0.2292, 0.0000, Test Score: 0.1852, 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jinyi/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jinyi/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 003, Train Score: 0.2332, 0.0000, Test Score: 0.1856, 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jinyi/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jinyi/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 004, Train Score: 0.2865, 0.0000, Test Score: 0.1926, 0.0000\n",
      "Epoch: 005, Train Score: 0.3896, 0.6809, Test Score: 0.2877, 0.5833\n",
      "Epoch: 006, Train Score: 0.4875, 0.8757, Test Score: 0.3058, 0.7500\n",
      "Epoch: 007, Train Score: 0.5346, 0.8367, Test Score: 0.3020, 0.6500\n",
      "Epoch: 008, Train Score: 0.5807, 0.8515, Test Score: 0.3101, 0.4848\n",
      "Epoch: 009, Train Score: 0.6275, 0.7766, Test Score: 0.3060, 0.3878\n",
      "Epoch: 010, Train Score: 0.6552, 0.8177, Test Score: 0.3067, 0.3390\n",
      "round 4, auc 0.3067466033543461\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jinyi/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jinyi/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Train Score: 0.2194, 0.0000, Test Score: 0.1835, 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jinyi/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jinyi/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 002, Train Score: 0.2238, 0.0000, Test Score: 0.1833, 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jinyi/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jinyi/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 003, Train Score: 0.2503, 0.0000, Test Score: 0.1750, 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jinyi/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jinyi/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 004, Train Score: 0.2858, 0.0000, Test Score: 0.2002, 0.0000\n",
      "Epoch: 005, Train Score: 0.3055, 0.9167, Test Score: 0.1890, 0.3333\n",
      "Epoch: 006, Train Score: 0.3830, 0.9032, Test Score: 0.2028, 0.3333\n",
      "Epoch: 007, Train Score: 0.4542, 0.7847, Test Score: 0.2134, 0.3333\n",
      "Epoch: 008, Train Score: 0.5770, 0.9010, Test Score: 0.2995, 0.7059\n",
      "Epoch: 009, Train Score: 0.6242, 0.8800, Test Score: 0.3205, 0.6957\n",
      "Epoch: 010, Train Score: 0.6446, 0.8491, Test Score: 0.3186, 0.5000\n",
      "round 5, auc 0.31861385610417825\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jinyi/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jinyi/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Train Score: 0.2234, 0.0000, Test Score: 0.1885, 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jinyi/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jinyi/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 002, Train Score: 0.2347, 0.0000, Test Score: 0.1833, 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jinyi/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jinyi/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 003, Train Score: 0.2836, 0.0000, Test Score: 0.2010, 0.0000\n",
      "Epoch: 004, Train Score: 0.2923, 1.0000, Test Score: 0.1982, 0.0000\n",
      "Epoch: 005, Train Score: 0.3364, 1.0000, Test Score: 0.1930, 0.0000\n",
      "Epoch: 006, Train Score: 0.3543, 0.9565, Test Score: 0.1927, 0.2000\n",
      "Epoch: 007, Train Score: 0.4776, 0.9388, Test Score: 0.2569, 0.6667\n",
      "Epoch: 008, Train Score: 0.5247, 0.8955, Test Score: 0.2903, 0.6500\n",
      "Epoch: 009, Train Score: 0.5666, 0.8613, Test Score: 0.2957, 0.4595\n",
      "Epoch: 010, Train Score: 0.5973, 0.9350, Test Score: 0.3051, 0.7000\n",
      "round 6, auc 0.30514202541598456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jinyi/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jinyi/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Train Score: 0.2227, 0.0000, Test Score: 0.1829, 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jinyi/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jinyi/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 002, Train Score: 0.2242, 0.0000, Test Score: 0.1900, 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jinyi/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jinyi/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 003, Train Score: 0.2430, 0.0000, Test Score: 0.1820, 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jinyi/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 004, Train Score: 0.2518, 1.0000, Test Score: 0.1945, 0.0000\n",
      "Epoch: 005, Train Score: 0.3113, 0.8261, Test Score: 0.2123, 0.3333\n",
      "Epoch: 006, Train Score: 0.4597, 0.8433, Test Score: 0.3101, 0.7500\n",
      "Epoch: 007, Train Score: 0.4999, 0.8806, Test Score: 0.2827, 0.7143\n",
      "Epoch: 008, Train Score: 0.5461, 0.8671, Test Score: 0.2885, 0.5200\n",
      "Epoch: 009, Train Score: 0.5786, 0.8930, Test Score: 0.2942, 0.4800\n",
      "Epoch: 010, Train Score: 0.6109, 0.7681, Test Score: 0.3033, 0.3585\n",
      "round 7, auc 0.3032742045667778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jinyi/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jinyi/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Train Score: 0.2208, 0.0000, Test Score: 0.1836, 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jinyi/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jinyi/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 002, Train Score: 0.2318, 0.0000, Test Score: 0.1815, 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jinyi/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jinyi/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 003, Train Score: 0.2310, 0.0000, Test Score: 0.1824, 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jinyi/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jinyi/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 004, Train Score: 0.3064, 0.0000, Test Score: 0.1945, 0.0000\n",
      "Epoch: 005, Train Score: 0.4638, 0.7423, Test Score: 0.3065, 0.6071\n",
      "Epoch: 006, Train Score: 0.5227, 0.7612, Test Score: 0.3093, 0.4750\n",
      "Epoch: 007, Train Score: 0.5772, 0.8987, Test Score: 0.3174, 0.7143\n",
      "Epoch: 008, Train Score: 0.6132, 0.8536, Test Score: 0.3149, 0.5455\n",
      "Epoch: 009, Train Score: 0.6450, 0.8072, Test Score: 0.2884, 0.3878\n",
      "Epoch: 010, Train Score: 0.6756, 0.7340, Test Score: 0.3081, 0.2737\n",
      "round 8, auc 0.30813978253430285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jinyi/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jinyi/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Train Score: 0.2237, 0.0000, Test Score: 0.1876, 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jinyi/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jinyi/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 002, Train Score: 0.2273, 0.0000, Test Score: 0.1976, 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jinyi/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jinyi/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 003, Train Score: 0.2324, 0.0000, Test Score: 0.1933, 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jinyi/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 004, Train Score: 0.2752, 1.0000, Test Score: 0.2122, 0.0000\n",
      "Epoch: 005, Train Score: 0.4261, 0.8951, Test Score: 0.3289, 0.8000\n",
      "Epoch: 006, Train Score: 0.4949, 0.9145, Test Score: 0.3111, 0.9167\n",
      "Epoch: 007, Train Score: 0.5427, 0.8900, Test Score: 0.3012, 0.8125\n",
      "Epoch: 008, Train Score: 0.5833, 0.7691, Test Score: 0.3026, 0.4884\n",
      "Epoch: 009, Train Score: 0.6248, 0.8288, Test Score: 0.3136, 0.5806\n",
      "Epoch: 010, Train Score: 0.6687, 0.8705, Test Score: 0.3178, 0.4865\n",
      "round 9, auc 0.31781531752428416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jinyi/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jinyi/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Train Score: 0.2210, 0.0000, Test Score: 0.1841, 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jinyi/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jinyi/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 002, Train Score: 0.2342, 0.0000, Test Score: 0.1848, 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jinyi/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jinyi/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 003, Train Score: 0.2550, 0.0000, Test Score: 0.1879, 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jinyi/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 004, Train Score: 0.3148, 1.0000, Test Score: 0.1996, 0.0000\n",
      "Epoch: 005, Train Score: 0.4237, 0.9262, Test Score: 0.3112, 0.8182\n",
      "Epoch: 006, Train Score: 0.5028, 0.8857, Test Score: 0.3045, 0.9000\n",
      "Epoch: 007, Train Score: 0.5594, 0.8423, Test Score: 0.3041, 0.6000\n",
      "Epoch: 008, Train Score: 0.5843, 0.7615, Test Score: 0.3001, 0.4324\n",
      "Epoch: 009, Train Score: 0.6268, 0.7922, Test Score: 0.2916, 0.4706\n",
      "Epoch: 010, Train Score: 0.6570, 0.7479, Test Score: 0.3005, 0.3667\n",
      "round 10, auc 0.3004758268098901\n",
      "4184.115975618362\n",
      "mean: 0.29671006775942754, std: 0.01941065581443842\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_curve, auc, precision_score\n",
    "import time\n",
    "\n",
    "optimizer = torch.optim.Adam(bitenet.parameters(), lr = 0.001)\n",
    "criterion = torch.nn.BCELoss()\n",
    "\n",
    "def bitenet_train(train_loader):\n",
    "    bitenet.train()\n",
    "    for data in train_loader:  # Iterate in batches over the training dataset.\n",
    "        x,t,y = data\n",
    "        pred_y = bitenet(x, t)\n",
    "        #print(pred_y.shape, pred_y.min(), pred_y.max())\n",
    "        loss = criterion(pred_y, y.float())\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "def bitenet_test(loader):\n",
    "    bitenet.eval()\n",
    "    pred = []\n",
    "    y_true = []\n",
    "    for data in loader:  # Iterate in batches over the training/test dataset.\n",
    "        x,t,y = data\n",
    "        out = bitenet(x, t)\n",
    "        pred +=  out.squeeze().tolist() \n",
    "        y_true += y.squeeze().tolist()\n",
    "    precision, recall, thresholds = precision_recall_curve(y_true, pred)\n",
    "    auc_score = auc(recall, precision)\n",
    "    y_pred = [p>0.5 for p in pred]\n",
    "    p_score = precision_score(y_true, y_pred)\n",
    "    return auc_score, p_score\n",
    " \n",
    "\n",
    "\n",
    "ts = time.time()\n",
    "auc_score = []\n",
    "for times in range(10):\n",
    "    bitenet.__init__()\n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer = torch.optim.Adam(bitenet.parameters(), lr=0.001)\n",
    "    for epoch in range(10):\n",
    "        bitenet_train(train_loader)\n",
    "        bitenet_train_acc = bitenet_test(train_loader)\n",
    "        bitenet_test_acc = bitenet_test(test_loader)\n",
    "        print(f'Epoch: {epoch + 1:03d}, Train Score: {bitenet_train_acc[0]:.4f}, {bitenet_train_acc[1]:.4f}, Test Score: {bitenet_test_acc[0]:.4f}, {bitenet_test_acc[1]:.4f}')\n",
    "    auc_score.append(bitenet_test_acc[0])\n",
    "    print(\"round {}, auc {}\".format(times+1, bitenet_test_acc[0]))\n",
    "        \n",
    "te = time.time()\n",
    "print(te-ts)\n",
    "auc_ = np.array(auc_score)\n",
    "print(\"mean: {}, std: {}\".format(np.mean(auc_), np.std(auc_)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3056c37-69da-4a56-ad01-313b93b21b44",
   "metadata": {},
   "source": [
    "## Part 4: Test for baseline models\n",
    "\n",
    "Use same data to predict with RNN and RETAIN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0b206fca-9360-49f5-8f55-2391399c224e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, num_codes):\n",
    "        super().__init__()\n",
    "        \n",
    "        #num_codes += 1\n",
    "        num_embedding = 50\n",
    "        \n",
    "        self.embedding = nn.Embedding(num_codes, num_embedding)\n",
    "        self.rnn = nn.GRU(num_embedding, hidden_size=num_embedding, batch_first=True, num_layers=5)\n",
    "        self.fc = nn.Linear(in_features=num_embedding, out_features=1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, code_input, interval_input):\n",
    "        batch_size = code_input.shape[0]\n",
    "        input_mask = (code_input != 0)\n",
    "        #x = torch.cat((code_input, interval_input[:,:,None]), -1)\n",
    "        x = self.embedding(code_input)\n",
    "        mask_ = input_mask.unsqueeze(3).repeat(1, 1, 1, x.shape[3])\n",
    "        sum_embeddings = torch.sum(x*mask_, 2)\n",
    "        output, _ = self.rnn(sum_embeddings)\n",
    "        \n",
    "        \n",
    "        visit_length = torch.sum(torch.sum(input_mask,2)>0, 1)\n",
    "        last_hidden_state = output[torch.arange(output.size(0)),visit_length-1,: ]\n",
    "        logits = self.fc(last_hidden_state)\n",
    "        probs = self.sigmoid(logits)\n",
    "        #return probs.view(batch_size)\n",
    "        return probs\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ffb29dce-c321-4291-bd1d-00e1b3580cce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Train Score: 0.4286, 0.0000, Test Score: 0.3248, 0.0000\n",
      "Epoch: 002, Train Score: 0.5302, 0.0000, Test Score: 0.3314, 0.0000\n",
      "Epoch: 003, Train Score: 0.6566, 0.0000, Test Score: 0.2917, 0.0000\n",
      "Epoch: 004, Train Score: 0.7594, 0.0000, Test Score: 0.3019, 0.0000\n",
      "Epoch: 005, Train Score: 0.8565, 0.0000, Test Score: 0.2925, 0.0000\n",
      "Epoch: 006, Train Score: 0.9177, 0.0000, Test Score: 0.2835, 0.0000\n",
      "Epoch: 007, Train Score: 0.9522, 0.0000, Test Score: 0.2802, 0.0000\n",
      "Epoch: 008, Train Score: 0.9701, 0.0000, Test Score: 0.3087, 0.0000\n",
      "Epoch: 009, Train Score: 0.9806, 0.0000, Test Score: 0.2843, 0.0000\n",
      "Epoch: 010, Train Score: 0.9843, 0.0000, Test Score: 0.2842, 0.0000\n",
      "round 1, auc 0.28419003445132524\n",
      "Epoch: 001, Train Score: 0.3930, 0.0000, Test Score: 0.2786, 0.0000\n",
      "Epoch: 002, Train Score: 0.4672, 0.0000, Test Score: 0.2834, 0.0000\n",
      "Epoch: 003, Train Score: 0.5763, 0.0000, Test Score: 0.2956, 0.0000\n",
      "Epoch: 004, Train Score: 0.6507, 0.0000, Test Score: 0.2763, 0.0000\n",
      "Epoch: 005, Train Score: 0.7103, 0.0000, Test Score: 0.2765, 0.0000\n",
      "Epoch: 006, Train Score: 0.7632, 0.0000, Test Score: 0.2624, 0.0000\n",
      "Epoch: 007, Train Score: 0.8142, 0.0000, Test Score: 0.2586, 0.0000\n",
      "Epoch: 008, Train Score: 0.8705, 0.0000, Test Score: 0.2446, 0.0000\n",
      "Epoch: 009, Train Score: 0.9178, 0.0000, Test Score: 0.2539, 0.0000\n",
      "Epoch: 010, Train Score: 0.9438, 0.0000, Test Score: 0.2740, 0.0000\n",
      "round 2, auc 0.27400688958937136\n",
      "Epoch: 001, Train Score: 0.4426, 0.0000, Test Score: 0.2778, 0.0000\n",
      "Epoch: 002, Train Score: 0.5726, 0.0000, Test Score: 0.2837, 0.0000\n",
      "Epoch: 003, Train Score: 0.7471, 0.0000, Test Score: 0.2882, 0.0000\n",
      "Epoch: 004, Train Score: 0.8412, 0.0000, Test Score: 0.2723, 0.0000\n",
      "Epoch: 005, Train Score: 0.9208, 0.0000, Test Score: 0.2727, 0.0000\n",
      "Epoch: 006, Train Score: 0.9429, 0.0000, Test Score: 0.2266, 0.0000\n",
      "Epoch: 007, Train Score: 0.9689, 0.0000, Test Score: 0.2639, 0.0000\n",
      "Epoch: 008, Train Score: 0.9761, 0.0000, Test Score: 0.2524, 0.0000\n",
      "Epoch: 009, Train Score: 0.9783, 0.0000, Test Score: 0.2547, 0.0000\n",
      "Epoch: 010, Train Score: 0.9806, 0.0000, Test Score: 0.2625, 0.0000\n",
      "round 3, auc 0.2625154334596852\n",
      "Epoch: 001, Train Score: 0.4416, 0.0000, Test Score: 0.3047, 0.0000\n",
      "Epoch: 002, Train Score: 0.5671, 0.0000, Test Score: 0.2815, 0.0000\n",
      "Epoch: 003, Train Score: 0.6967, 0.0000, Test Score: 0.3116, 0.0000\n",
      "Epoch: 004, Train Score: 0.7898, 0.0000, Test Score: 0.2810, 0.0000\n",
      "Epoch: 005, Train Score: 0.8582, 0.0000, Test Score: 0.2561, 0.0000\n",
      "Epoch: 006, Train Score: 0.9156, 0.0000, Test Score: 0.2670, 0.0000\n",
      "Epoch: 007, Train Score: 0.9391, 0.0000, Test Score: 0.2480, 0.0000\n",
      "Epoch: 008, Train Score: 0.9574, 0.0000, Test Score: 0.2417, 0.0000\n",
      "Epoch: 009, Train Score: 0.9667, 0.0000, Test Score: 0.2385, 0.0000\n",
      "Epoch: 010, Train Score: 0.9689, 0.0000, Test Score: 0.2459, 0.0000\n",
      "round 4, auc 0.24586196504707342\n",
      "Epoch: 001, Train Score: 0.4379, 0.0000, Test Score: 0.2887, 0.0000\n",
      "Epoch: 002, Train Score: 0.5588, 0.0000, Test Score: 0.2594, 0.0000\n",
      "Epoch: 003, Train Score: 0.7566, 0.0000, Test Score: 0.2856, 0.0000\n",
      "Epoch: 004, Train Score: 0.8410, 0.0000, Test Score: 0.2813, 0.0000\n",
      "Epoch: 005, Train Score: 0.8964, 0.0000, Test Score: 0.2550, 0.0000\n",
      "Epoch: 006, Train Score: 0.9209, 0.0000, Test Score: 0.2570, 0.0000\n",
      "Epoch: 007, Train Score: 0.9393, 0.0000, Test Score: 0.2280, 0.0000\n",
      "Epoch: 008, Train Score: 0.9493, 0.0000, Test Score: 0.2421, 0.0000\n",
      "Epoch: 009, Train Score: 0.9631, 0.0000, Test Score: 0.2302, 0.0000\n",
      "Epoch: 010, Train Score: 0.9692, 0.0000, Test Score: 0.2252, 0.0000\n",
      "round 5, auc 0.2252128682283066\n",
      "Epoch: 001, Train Score: 0.4157, 0.0000, Test Score: 0.3090, 0.0000\n",
      "Epoch: 002, Train Score: 0.5149, 0.0000, Test Score: 0.3114, 0.0000\n",
      "Epoch: 003, Train Score: 0.6146, 0.0000, Test Score: 0.2826, 0.0000\n",
      "Epoch: 004, Train Score: 0.7495, 0.0000, Test Score: 0.2782, 0.0000\n",
      "Epoch: 005, Train Score: 0.8374, 0.0000, Test Score: 0.2847, 0.0000\n",
      "Epoch: 006, Train Score: 0.9050, 0.0000, Test Score: 0.3282, 0.0000\n",
      "Epoch: 007, Train Score: 0.9498, 0.0000, Test Score: 0.2947, 0.0000\n",
      "Epoch: 008, Train Score: 0.9679, 0.0000, Test Score: 0.2973, 0.0000\n",
      "Epoch: 009, Train Score: 0.9824, 0.0000, Test Score: 0.2963, 0.0000\n",
      "Epoch: 010, Train Score: 0.9848, 0.0000, Test Score: 0.3258, 0.0000\n",
      "round 6, auc 0.32575873732838273\n",
      "Epoch: 001, Train Score: 0.3850, 0.0000, Test Score: 0.2889, 0.0000\n",
      "Epoch: 002, Train Score: 0.5246, 0.0000, Test Score: 0.2856, 0.0000\n",
      "Epoch: 003, Train Score: 0.6849, 0.0000, Test Score: 0.2683, 0.0000\n",
      "Epoch: 004, Train Score: 0.8318, 0.0000, Test Score: 0.2677, 0.0000\n",
      "Epoch: 005, Train Score: 0.9006, 0.0000, Test Score: 0.2560, 0.0000\n",
      "Epoch: 006, Train Score: 0.9378, 0.0000, Test Score: 0.2426, 0.0000\n",
      "Epoch: 007, Train Score: 0.9606, 0.0000, Test Score: 0.2226, 0.0000\n",
      "Epoch: 008, Train Score: 0.9701, 0.0000, Test Score: 0.2089, 0.0000\n",
      "Epoch: 009, Train Score: 0.9820, 0.0000, Test Score: 0.2121, 0.0000\n",
      "Epoch: 010, Train Score: 0.9845, 0.0000, Test Score: 0.2187, 0.0000\n",
      "round 7, auc 0.21867059327521066\n",
      "Epoch: 001, Train Score: 0.4255, 0.0000, Test Score: 0.2944, 0.0000\n",
      "Epoch: 002, Train Score: 0.5656, 0.0000, Test Score: 0.3077, 0.0000\n",
      "Epoch: 003, Train Score: 0.7196, 0.0000, Test Score: 0.3066, 0.0000\n",
      "Epoch: 004, Train Score: 0.8152, 0.0000, Test Score: 0.2991, 0.0000\n",
      "Epoch: 005, Train Score: 0.8727, 0.0000, Test Score: 0.3058, 0.0000\n",
      "Epoch: 006, Train Score: 0.9119, 0.0000, Test Score: 0.3188, 0.0000\n",
      "Epoch: 007, Train Score: 0.9315, 0.0000, Test Score: 0.3064, 0.0000\n",
      "Epoch: 008, Train Score: 0.9442, 0.0000, Test Score: 0.2987, 0.0000\n",
      "Epoch: 009, Train Score: 0.9553, 0.0000, Test Score: 0.3053, 0.0000\n",
      "Epoch: 010, Train Score: 0.9624, 0.0000, Test Score: 0.3196, 0.0000\n",
      "round 8, auc 0.31959220465083216\n",
      "Epoch: 001, Train Score: 0.4230, 0.0000, Test Score: 0.2772, 0.0000\n",
      "Epoch: 002, Train Score: 0.5779, 0.0000, Test Score: 0.3102, 0.0000\n",
      "Epoch: 003, Train Score: 0.7430, 0.0000, Test Score: 0.3006, 0.0000\n",
      "Epoch: 004, Train Score: 0.8341, 0.0000, Test Score: 0.3028, 0.0000\n",
      "Epoch: 005, Train Score: 0.8950, 0.0000, Test Score: 0.2855, 0.0000\n",
      "Epoch: 006, Train Score: 0.9230, 0.0000, Test Score: 0.3244, 0.0000\n",
      "Epoch: 007, Train Score: 0.9506, 0.0000, Test Score: 0.2732, 0.0000\n",
      "Epoch: 008, Train Score: 0.9586, 0.0000, Test Score: 0.2716, 0.0000\n",
      "Epoch: 009, Train Score: 0.9680, 0.0000, Test Score: 0.2774, 0.0000\n",
      "Epoch: 010, Train Score: 0.9716, 0.0000, Test Score: 0.2716, 0.0000\n",
      "round 9, auc 0.2715669374503671\n",
      "Epoch: 001, Train Score: 0.4284, 0.0000, Test Score: 0.2705, 0.0000\n",
      "Epoch: 002, Train Score: 0.5614, 0.0000, Test Score: 0.2673, 0.0000\n",
      "Epoch: 003, Train Score: 0.7429, 0.0000, Test Score: 0.2779, 0.0000\n",
      "Epoch: 004, Train Score: 0.8555, 0.0000, Test Score: 0.2564, 0.0000\n",
      "Epoch: 005, Train Score: 0.9097, 0.0000, Test Score: 0.2792, 0.0000\n",
      "Epoch: 006, Train Score: 0.9415, 0.0000, Test Score: 0.2823, 0.0000\n",
      "Epoch: 007, Train Score: 0.9557, 0.0000, Test Score: 0.2480, 0.0000\n",
      "Epoch: 008, Train Score: 0.9624, 0.0000, Test Score: 0.2426, 0.0000\n",
      "Epoch: 009, Train Score: 0.9673, 0.0000, Test Score: 0.2468, 0.0000\n",
      "Epoch: 010, Train Score: 0.9738, 0.0000, Test Score: 0.2375, 0.0000\n",
      "round 10, auc 0.23748804383051605\n",
      "496.97870683670044\n",
      "mean: 0.26648637073110704, std: 0.03464263429328576\n"
     ]
    }
   ],
   "source": [
    "baseline_rnn = RNN(num_codes = 2438)\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(baseline_rnn.parameters(), lr=0.001)\n",
    "\n",
    "def rnn_train(train_loader):\n",
    "    baseline_rnn.train()\n",
    "    for data in train_loader:  # Iterate in batches over the training dataset.\n",
    "        x,t,y = data\n",
    "        pred_y = baseline_rnn(x, t)\n",
    "        #print(pred_y.shape, pred_y.min(), pred_y.max())\n",
    "        loss = criterion(pred_y, y.float())\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "def rnn_test(loader):\n",
    "    baseline_rnn.eval()\n",
    "    pred = []\n",
    "    y_true = []\n",
    "    for data in loader:  # Iterate in batches over the training/test dataset.\n",
    "        x,t,y = data\n",
    "        out = baseline_rnn(x, t)\n",
    "        pred +=  out.squeeze().tolist() \n",
    "        y_true += y.squeeze().tolist()\n",
    "    precision, recall, thresholds = precision_recall_curve(y_true, pred)\n",
    "    auc_score = auc(recall, precision)\n",
    "    y_pred = [p>0.5 for p in pred]\n",
    "    #p_score = precision_score(y_true, y_pred)\n",
    "    p_score = 0\n",
    "    return auc_score, p_score\n",
    " \n",
    "\n",
    "ts = time.time()\n",
    "auc_score = []\n",
    "for times in range(10):\n",
    "    baseline_rnn.__init__(num_codes = 2438)\n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer = torch.optim.Adam(baseline_rnn.parameters(), lr=0.001)\n",
    "    for epoch in range(10):\n",
    "        rnn_train(train_loader)\n",
    "        rnn_train_acc = rnn_test(train_loader)\n",
    "        rnn_test_acc = rnn_test(test_loader)\n",
    "        print(f'Epoch: {epoch + 1:03d}, Train Score: {rnn_train_acc[0]:.4f}, {rnn_train_acc[1]:.4f}, Test Score: {rnn_test_acc[0]:.4f}, {rnn_test_acc[1]:.4f}')\n",
    "    auc_score.append(rnn_test_acc[0])\n",
    "    print(\"round {}, auc {}\".format(times+1, rnn_test_acc[0]))\n",
    "        \n",
    "te = time.time()\n",
    "print(te-ts)\n",
    "auc_ = np.array(auc_score)\n",
    "print(\"mean: {}, std: {}\".format(np.mean(auc_), np.std(auc_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b243c1b7-6d15-48c5-a490-6b7017002e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AlphaAttention(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, embedding_dim):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.a_att = nn.Linear(embedding_dim, 1)\n",
    "\n",
    "    def forward(self, g, rev_masks):\n",
    "\n",
    "        score = self.a_att(g)\n",
    "        mask = (rev_masks.sum(2)>0).unsqueeze(2)\n",
    "        score = score * mask + (~mask)*(-1e9)\n",
    "        att_value = torch.nn.functional.softmax(score, dim=1)\n",
    "        #print(att_value.shape)\n",
    "        return att_value\n",
    "    \n",
    "class BetaAttention(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, embedding_dim):\n",
    "        super().__init__()\n",
    "\n",
    "        self.b_att = nn.Linear(embedding_dim, embedding_dim)\n",
    "\n",
    "\n",
    "    def forward(self, h):\n",
    "\n",
    "        score = self.b_att(h)\n",
    "        beta = torch.tanh(score)\n",
    "        #print(beta.shape)\n",
    "        return beta\n",
    "\n",
    "def attention_sum(alpha, beta, rev_v, rev_masks):\n",
    "    \n",
    "    mask = (rev_masks.sum(2)>0).unsqueeze(2).repeat(1,1,beta.shape[-1])\n",
    "    a = alpha.repeat(1,1,beta.shape[-1])\n",
    "    #print(beta.shape, a.shape, mask.shape, rev_v.shape)\n",
    "    c = (rev_v * mask * a * beta).sum(1)\n",
    "    return c\n",
    "\n",
    "class retain(torch.nn.Module):\n",
    "    def __init__(self, num_codes, embedding_dim=50):\n",
    "        super().__init__()\n",
    "        # Define the embedding layer using `nn.Embedding`. Set `embDimSize` to 128.\n",
    "        self.embedding = nn.Embedding(num_codes, embedding_dim)\n",
    "        # Define the RNN-alpha using `nn.GRU()`; Set `hidden_size` to 128. Set `batch_first` to True.\n",
    "        self.rnn_a = nn.GRU(embedding_dim, embedding_dim, batch_first=True, num_layers=2)\n",
    "        # Define the RNN-beta using `nn.GRU()`; Set `hidden_size` to 128. Set `batch_first` to True.\n",
    "        self.rnn_b = nn.GRU(embedding_dim, embedding_dim, batch_first=True, num_layers=2)\n",
    "        # Define the alpha-attention using `AlphaAttention()`;\n",
    "        self.att_a = AlphaAttention(embedding_dim)\n",
    "        # Define the beta-attention using `BetaAttention()`;\n",
    "        self.att_b = BetaAttention(embedding_dim)\n",
    "        # Define the linear layers using `nn.Linear()`;\n",
    "        self.fc = nn.Linear(embedding_dim, 1)\n",
    "        # Define the final activation layer using `nn.Sigmoid().\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, x, t):\n",
    "        masks = (x != 0)\n",
    "        # 1. Pass the reversed sequence through the embedding layer;\n",
    "        x = self.embedding(x)\n",
    "        # 2. Sum the reversed embeddings for each diagnosis code up for a visit of a patient.\n",
    "        \n",
    "        x = x * masks.unsqueeze(-1)\n",
    "        x = torch.sum(x, dim = -2)\n",
    "        # 3. Pass the reversed embegginds through the RNN-alpha and RNN-beta layer separately;\n",
    "        g, _ = self.rnn_a(x)\n",
    "        h, _ = self.rnn_b(x)\n",
    "        # 4. Obtain the alpha and beta attentions using `AlphaAttention()` and `BetaAttention()`;\n",
    "        alpha = self.att_a(g, masks)\n",
    "        beta = self.att_b(h)\n",
    "        # 5. Sum the attention up using `attention_sum()`;\n",
    "        c = attention_sum(alpha, beta, x, masks)\n",
    "        # 6. Pass the context vector through the linear and activation layers.\n",
    "        logits = self.fc(c)\n",
    "        probs = self.sigmoid(logits)\n",
    "        return probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5e2a4e20-0fa6-41d1-b854-f247d7cb8b0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Train Score: 0.4437, 0.9785, Test Score: 0.2930, 1.0000\n",
      "Epoch: 002, Train Score: 0.6482, 0.9669, Test Score: 0.2944, 0.6250\n",
      "Epoch: 003, Train Score: 0.8000, 0.9769, Test Score: 0.2886, 0.5500\n",
      "Epoch: 004, Train Score: 0.9180, 0.9650, Test Score: 0.2830, 0.3269\n",
      "Epoch: 005, Train Score: 0.9635, 0.9701, Test Score: 0.2640, 0.2436\n",
      "Epoch: 006, Train Score: 0.9872, 0.9807, Test Score: 0.2581, 0.2453\n",
      "Epoch: 007, Train Score: 0.9964, 0.9983, Test Score: 0.2408, 0.2474\n",
      "Epoch: 008, Train Score: 0.9990, 0.9983, Test Score: 0.2542, 0.2444\n",
      "Epoch: 009, Train Score: 0.9997, 1.0000, Test Score: 0.2571, 0.2667\n",
      "Epoch: 010, Train Score: 0.9999, 1.0000, Test Score: 0.2508, 0.2593\n",
      "round 1, auc 0.2508003516919891\n",
      "Epoch: 001, Train Score: 0.4103, 1.0000, Test Score: 0.2875, 0.7500\n",
      "Epoch: 002, Train Score: 0.6376, 0.9617, Test Score: 0.2936, 0.6875\n",
      "Epoch: 003, Train Score: 0.8174, 0.9261, Test Score: 0.2699, 0.3019\n",
      "Epoch: 004, Train Score: 0.9252, 0.9681, Test Score: 0.2696, 0.2973\n",
      "Epoch: 005, Train Score: 0.9693, 0.9841, Test Score: 0.2800, 0.3026\n",
      "Epoch: 006, Train Score: 0.9880, 0.9954, Test Score: 0.2739, 0.3151\n",
      "Epoch: 007, Train Score: 0.9965, 0.9983, Test Score: 0.2645, 0.2547\n",
      "Epoch: 008, Train Score: 0.9986, 1.0000, Test Score: 0.2459, 0.2477\n",
      "Epoch: 009, Train Score: 0.9997, 1.0000, Test Score: 0.2462, 0.2477\n",
      "Epoch: 010, Train Score: 0.9999, 1.0000, Test Score: 0.2444, 0.2430\n",
      "round 2, auc 0.2443878044601825\n",
      "Epoch: 001, Train Score: 0.4158, 0.9219, Test Score: 0.3125, 0.9000\n",
      "Epoch: 002, Train Score: 0.6484, 0.9444, Test Score: 0.2955, 0.7143\n",
      "Epoch: 003, Train Score: 0.8327, 0.9640, Test Score: 0.2796, 0.5185\n",
      "Epoch: 004, Train Score: 0.9300, 0.9756, Test Score: 0.2819, 0.3947\n",
      "Epoch: 005, Train Score: 0.9713, 0.9790, Test Score: 0.2672, 0.3220\n",
      "Epoch: 006, Train Score: 0.9888, 0.9867, Test Score: 0.2648, 0.3235\n",
      "Epoch: 007, Train Score: 0.9960, 0.9941, Test Score: 0.2615, 0.2895\n",
      "Epoch: 008, Train Score: 0.9988, 0.9967, Test Score: 0.2733, 0.3333\n",
      "Epoch: 009, Train Score: 0.9997, 0.9959, Test Score: 0.2583, 0.2717\n",
      "Epoch: 010, Train Score: 0.9999, 0.9976, Test Score: 0.2615, 0.2841\n",
      "round 3, auc 0.2615427015882902\n",
      "Epoch: 001, Train Score: 0.4002, 0.9519, Test Score: 0.3157, 1.0000\n",
      "Epoch: 002, Train Score: 0.5872, 0.9468, Test Score: 0.3255, 0.8182\n",
      "Epoch: 003, Train Score: 0.7900, 0.9683, Test Score: 0.3027, 0.5333\n",
      "Epoch: 004, Train Score: 0.8934, 0.9843, Test Score: 0.2989, 0.3673\n",
      "Epoch: 005, Train Score: 0.9563, 0.9722, Test Score: 0.2706, 0.2812\n",
      "Epoch: 006, Train Score: 0.9800, 0.9914, Test Score: 0.2711, 0.2561\n",
      "Epoch: 007, Train Score: 0.9934, 0.9914, Test Score: 0.2723, 0.2845\n",
      "Epoch: 008, Train Score: 0.9957, 0.9795, Test Score: 0.2621, 0.2374\n",
      "Epoch: 009, Train Score: 0.9993, 1.0000, Test Score: 0.2681, 0.2636\n",
      "Epoch: 010, Train Score: 0.9998, 0.9992, Test Score: 0.2666, 0.2653\n",
      "round 4, auc 0.26658358379222674\n",
      "Epoch: 001, Train Score: 0.4093, 0.9875, Test Score: 0.3017, 1.0000\n",
      "Epoch: 002, Train Score: 0.6000, 0.9689, Test Score: 0.3093, 0.8333\n",
      "Epoch: 003, Train Score: 0.8051, 0.9378, Test Score: 0.3038, 0.5000\n",
      "Epoch: 004, Train Score: 0.9022, 0.9154, Test Score: 0.2879, 0.3380\n",
      "Epoch: 005, Train Score: 0.9649, 0.9865, Test Score: 0.3017, 0.3696\n",
      "Epoch: 006, Train Score: 0.9859, 0.9831, Test Score: 0.2741, 0.2791\n",
      "Epoch: 007, Train Score: 0.9951, 0.9966, Test Score: 0.2911, 0.3077\n",
      "Epoch: 008, Train Score: 0.9981, 0.9983, Test Score: 0.2848, 0.3846\n",
      "Epoch: 009, Train Score: 0.9994, 1.0000, Test Score: 0.2798, 0.3256\n",
      "Epoch: 010, Train Score: 0.9998, 1.0000, Test Score: 0.2964, 0.3293\n",
      "round 5, auc 0.29642872570020407\n",
      "Epoch: 001, Train Score: 0.4024, 0.9389, Test Score: 0.3179, 1.0000\n",
      "Epoch: 002, Train Score: 0.5970, 0.9453, Test Score: 0.2981, 0.9167\n",
      "Epoch: 003, Train Score: 0.8051, 0.9712, Test Score: 0.2930, 0.6000\n",
      "Epoch: 004, Train Score: 0.9123, 0.9429, Test Score: 0.2796, 0.3111\n",
      "Epoch: 005, Train Score: 0.9641, 0.9806, Test Score: 0.2637, 0.3051\n",
      "Epoch: 006, Train Score: 0.9866, 0.9891, Test Score: 0.2591, 0.2464\n",
      "Epoch: 007, Train Score: 0.9935, 0.9841, Test Score: 0.2470, 0.2300\n",
      "Epoch: 008, Train Score: 0.9987, 0.9975, Test Score: 0.2589, 0.2838\n",
      "Epoch: 009, Train Score: 0.9994, 0.9976, Test Score: 0.2493, 0.2763\n",
      "Epoch: 010, Train Score: 0.9997, 0.9992, Test Score: 0.2564, 0.2778\n",
      "round 6, auc 0.2564156704800924\n",
      "Epoch: 001, Train Score: 0.4115, 0.9904, Test Score: 0.3182, 1.0000\n",
      "Epoch: 002, Train Score: 0.6165, 0.9778, Test Score: 0.3091, 0.6667\n",
      "Epoch: 003, Train Score: 0.8210, 0.9573, Test Score: 0.3056, 0.4118\n",
      "Epoch: 004, Train Score: 0.9167, 0.9437, Test Score: 0.2881, 0.3182\n",
      "Epoch: 005, Train Score: 0.9657, 0.9848, Test Score: 0.2966, 0.3378\n",
      "Epoch: 006, Train Score: 0.9864, 0.9891, Test Score: 0.2965, 0.2935\n",
      "Epoch: 007, Train Score: 0.9960, 0.9957, Test Score: 0.3034, 0.3412\n",
      "Epoch: 008, Train Score: 0.9989, 0.9975, Test Score: 0.3097, 0.3678\n",
      "Epoch: 009, Train Score: 0.9998, 0.9992, Test Score: 0.3117, 0.3505\n",
      "Epoch: 010, Train Score: 1.0000, 0.9992, Test Score: 0.3099, 0.3241\n",
      "round 7, auc 0.3099210725655408\n",
      "Epoch: 001, Train Score: 0.4208, 0.9896, Test Score: 0.3172, 0.8750\n",
      "Epoch: 002, Train Score: 0.6712, 0.9371, Test Score: 0.2936, 0.6316\n",
      "Epoch: 003, Train Score: 0.8526, 0.9693, Test Score: 0.2888, 0.4054\n",
      "Epoch: 004, Train Score: 0.9378, 0.9681, Test Score: 0.2934, 0.3182\n",
      "Epoch: 005, Train Score: 0.9742, 0.9699, Test Score: 0.2808, 0.2700\n",
      "Epoch: 006, Train Score: 0.9922, 0.9913, Test Score: 0.2707, 0.2522\n",
      "Epoch: 007, Train Score: 0.9974, 0.9958, Test Score: 0.2808, 0.2414\n",
      "Epoch: 008, Train Score: 0.9995, 0.9984, Test Score: 0.2891, 0.2609\n",
      "Epoch: 009, Train Score: 0.9999, 0.9992, Test Score: 0.2851, 0.2581\n",
      "Epoch: 010, Train Score: 1.0000, 0.9992, Test Score: 0.2903, 0.2636\n",
      "round 8, auc 0.2902634176276684\n",
      "Epoch: 001, Train Score: 0.4140, 0.9732, Test Score: 0.2929, 1.0000\n",
      "Epoch: 002, Train Score: 0.6305, 0.9200, Test Score: 0.2681, 0.4762\n",
      "Epoch: 003, Train Score: 0.8268, 0.9814, Test Score: 0.2740, 0.6111\n",
      "Epoch: 004, Train Score: 0.9230, 0.9688, Test Score: 0.2753, 0.2951\n",
      "Epoch: 005, Train Score: 0.9697, 0.9752, Test Score: 0.2667, 0.2250\n",
      "Epoch: 006, Train Score: 0.9898, 0.9956, Test Score: 0.2756, 0.2632\n",
      "Epoch: 007, Train Score: 0.9957, 0.9925, Test Score: 0.2783, 0.2593\n",
      "Epoch: 008, Train Score: 0.9980, 0.9983, Test Score: 0.2765, 0.2400\n",
      "Epoch: 009, Train Score: 0.9993, 0.9992, Test Score: 0.2863, 0.2796\n",
      "Epoch: 010, Train Score: 0.9998, 0.9992, Test Score: 0.2851, 0.2688\n",
      "round 9, auc 0.2851166216461222\n",
      "Epoch: 001, Train Score: 0.4166, 0.9643, Test Score: 0.2753, 0.7000\n",
      "Epoch: 002, Train Score: 0.6272, 0.9631, Test Score: 0.3016, 0.7143\n",
      "Epoch: 003, Train Score: 0.8172, 0.9350, Test Score: 0.2870, 0.3846\n",
      "Epoch: 004, Train Score: 0.9253, 0.9756, Test Score: 0.2856, 0.4118\n",
      "Epoch: 005, Train Score: 0.9704, 0.9826, Test Score: 0.2927, 0.3077\n",
      "Epoch: 006, Train Score: 0.9882, 0.9910, Test Score: 0.2853, 0.3077\n",
      "Epoch: 007, Train Score: 0.9958, 0.9940, Test Score: 0.2832, 0.2979\n",
      "Epoch: 008, Train Score: 0.9989, 0.9975, Test Score: 0.2756, 0.3048\n",
      "Epoch: 009, Train Score: 0.9997, 1.0000, Test Score: 0.2806, 0.2917\n",
      "Epoch: 010, Train Score: 0.9999, 1.0000, Test Score: 0.2828, 0.2737\n",
      "round 10, auc 0.2828065881393815\n",
      "403.18000769615173\n",
      "mean: 0.27442665376916975, std: 0.02047360946406823\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_curve, auc, precision_score\n",
    "baseline_retain = retain(num_codes = 2438)\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(baseline_retain.parameters(), lr=0.001)\n",
    "\n",
    "def retain_train(train_loader):\n",
    "    baseline_retain.train()\n",
    "    for data in train_loader:  # Iterate in batches over the training dataset.\n",
    "        x,t,y = data\n",
    "        pred_y = baseline_retain(x, t)\n",
    "        #print(pred_y.shape, pred_y.min(), pred_y.max())\n",
    "        loss = criterion(pred_y, y.float())\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "def retain_test(loader):\n",
    "    baseline_retain.eval()\n",
    "    pred = []\n",
    "    y_true = []\n",
    "    for data in loader:  # Iterate in batches over the training/test dataset.\n",
    "        x,t,y = data\n",
    "        out = baseline_retain(x, t)\n",
    "        pred +=  out.squeeze().tolist() \n",
    "        y_true += y.squeeze().tolist()\n",
    "    precision, recall, thresholds = precision_recall_curve(y_true, pred)\n",
    "    auc_score = auc(recall, precision)\n",
    "    y_pred = [p>0.5 for p in pred]\n",
    "    p_score = precision_score(y_true, y_pred)\n",
    "    return auc_score, p_score\n",
    " \n",
    "\n",
    "ts = time.time()\n",
    "auc_score = []\n",
    "for times in range(10):\n",
    "    baseline_retain.__init__(num_codes = 2438)\n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer = torch.optim.Adam(baseline_retain.parameters(), lr=0.001)\n",
    "    for epoch in range(10):\n",
    "        retain_train(train_loader)\n",
    "        retain_train_acc = retain_test(train_loader)\n",
    "        retain_test_acc = retain_test(test_loader)\n",
    "        print(f'Epoch: {epoch + 1:03d}, Train Score: {retain_train_acc[0]:.4f}, {retain_train_acc[1]:.4f}, Test Score: {retain_test_acc[0]:.4f}, {retain_test_acc[1]:.4f}')\n",
    "    auc_score.append(retain_test_acc[0])\n",
    "    print(\"round {}, auc {}\".format(times+1, retain_test_acc[0]))\n",
    "        \n",
    "te = time.time()\n",
    "print(te-ts)\n",
    "auc_ = np.array(auc_score)\n",
    "print(\"mean: {}, std: {}\".format(np.mean(auc_), np.std(auc_)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c79b3b52-7f36-4b5b-916f-03e5a9c286ea",
   "metadata": {},
   "source": [
    "### Score for BiteNet, RNN, Retain are 0.2967, 0.2665, 0.2744. BiteNet performs best."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77993c2e-2f7f-4894-9d0d-fd8704d3a441",
   "metadata": {},
   "source": [
    "## Ablation study\n",
    "\n",
    "Replace MasEnc blocks with simple muti-head attention layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "aa610e9c-db3f-4eb6-9de4-aa5a914558f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class multi_attn(torch.nn.Module):\n",
    "    def __init__(self, input_dim, embed_dim, num_heads):\n",
    "        super().__init__()\n",
    "\n",
    "        self.embed_dim = embed_dim\n",
    "        self.num_heads = num_heads\n",
    "        #self.atten_mask = attn_mask\n",
    "\n",
    "        \n",
    "        self.q_linear = nn.Linear(input_dim, embed_dim, bias = False)\n",
    "        self.k_linear = nn.Linear(input_dim, embed_dim, bias = False)\n",
    "        self.v_linear = nn.Linear(input_dim, embed_dim, bias = False)\n",
    "        \n",
    "        self.mulatt = nn.MultiheadAttention(embed_dim = self.embed_dim, num_heads = self.num_heads, batch_first = True)\n",
    "        \n",
    "    \n",
    "    def forward(self, x, input_mask):\n",
    "        queries = x\n",
    "        keys = x\n",
    "        \n",
    "        q = self.q_linear(queries)  # (N, L_q, d)\n",
    "        k = self.k_linear(keys)  # (N, L_k, d)\n",
    "        v = self.v_linear(keys)  # (N, L_k, d)\n",
    "              \n",
    "        \n",
    "        #data = self.mulatt(q, k, v, key_padding_mask = ~input_mask, attn_mask = attn_mask, need_weights = False)\n",
    "        data = self.mulatt(q, k, v, need_weights = False)\n",
    "        \n",
    "        \n",
    "        return data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "388ac1eb-b396-4033-b415-edac612005fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiteNet_ablation(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.lr = 0.0001\n",
    "        self.dropout_rate = 0.1\n",
    "        self.n_intervals = 12 * 365 + 1\n",
    "        self.n_visits = 10\n",
    "        self.n_codes = 39\n",
    "        self.vocabulary_size = 2438\n",
    "        self.digit3_size = 2438\n",
    "        self.pos_encoding = None\n",
    "        self.embedding_size = 50\n",
    "        self.num_hidden_layers = 2\n",
    "        self.num_heads = 2\n",
    "        self.batch = 32\n",
    "        \n",
    "        self.hidden_size = self.embedding_size\n",
    "        self.filter_size = self.embedding_size\n",
    "        \n",
    "        self.code_embedding_layer = torch.nn.Embedding(self.vocabulary_size, self.embedding_size) \n",
    "        self.interval_embedding_layer = torch.nn.Embedding(self.n_intervals, self.embedding_size) \n",
    "        '''self.common_layer1 = EncoderStack(self.embedding_size, self.embedding_size, self.num_heads, 'diag', \n",
    "                                          self.num_hidden_layers, self.batch * self.n_visits, self.n_codes, \n",
    "                                          self.hidden_size, self.filter_size, self.dropout_rate)'''\n",
    "        self.common_layer1 = multi_attn(self.embedding_size, self.embedding_size, self.num_heads)\n",
    "        self.attn_pool_layer1 = AttentionPooling(self.embedding_size)\n",
    "        '''self.common_layer2 = EncoderStack(self.embedding_size, self.embedding_size, self.num_heads, 'forward', \n",
    "                                          self.num_hidden_layers, self.batch, self.n_visits, \n",
    "                                          self.hidden_size, self.filter_size, self.dropout_rate)\n",
    "        self.common_layer3 = EncoderStack(self.embedding_size, self.embedding_size, self.num_heads, 'backward', \n",
    "                                          self.num_hidden_layers, self.batch, self.n_visits, \n",
    "                                          self.hidden_size, self.filter_size, self.dropout_rate)'''\n",
    "        self.common_layer2 = multi_attn(self.embedding_size, self.embedding_size, self.num_heads)\n",
    "        self.common_layer3 = multi_attn(self.embedding_size, self.embedding_size, self.num_heads)\n",
    "        \n",
    "        \n",
    "        self.attn_pool_layer2 = AttentionPooling(self.embedding_size)\n",
    "        self.attn_pool_layer3 = AttentionPooling(self.embedding_size)\n",
    "        self.fc1 = nn.Linear(2*self.embedding_size, 2*self.embedding_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(self.dropout_rate)\n",
    "        self.fc2 = nn.Linear(2*self.embedding_size,1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    def forward(self, code_input, interval_input):\n",
    "        inputs_mask = (code_input != 0)\n",
    "        visit_mask = (code_input.sum(-1) != 0)\n",
    "        \n",
    "        # shape [batch_size, n_visits, n_codes, embedding_size]\n",
    "        code_embed = self.code_embedding_layer(code_input)\n",
    "        # reshape to (batch*n_visit, n_codes, embedding_size)\n",
    "        e = code_embed.reshape(code_embed.shape[0]*code_embed.shape[1],code_embed.shape[2],code_embed.shape[3])\n",
    "        \n",
    "        #print(\"e: \", e.shape, e.min(), e.max())\n",
    "        # reshape to (batch*n_visit, n_codes)\n",
    "        e_mask = inputs_mask.reshape(inputs_mask.shape[0]*inputs_mask.shape[1],inputs_mask.shape[2])\n",
    "        \n",
    "        h = self.common_layer1(e, e_mask)\n",
    "        \n",
    "        #print(\"h: \", h.shape, h.min(), h.max())\n",
    "        \n",
    "        v = self.attn_pool_layer1(h, e_mask)\n",
    "        #print(\"v: \", v.shape, v.min(), v.max())\n",
    "        \n",
    "        # reshape to (batch, n_visit, embedding_size)\n",
    "        v = v.reshape(code_input.shape[0],code_input.shape[1],self.embedding_size)\n",
    "        \n",
    "        e_p = self.interval_embedding_layer(interval_input)\n",
    "        \n",
    "        \n",
    "        v = v + e_p\n",
    "        #print(\"v: \", v.shape, v.min(), v.max())\n",
    "        \n",
    "        \n",
    "        o_fw = self.common_layer2(v, visit_mask)\n",
    "        #print(\"o_fw: \", o_fw.shape, o_fw.min(), o_fw.max())\n",
    "        u_fw = self.attn_pool_layer2(o_fw, visit_mask)\n",
    "        #print(\"u_fw: \", u_fw.shape, u_fw.min(), u_fw.max())\n",
    "        o_bw = self.common_layer3(v, visit_mask)\n",
    "        #print(\"o_bw: \", o_bw.shape, o_bw.min(), o_bw.max())\n",
    "        u_bw = self.attn_pool_layer3(o_bw, visit_mask)\n",
    "        #print(\"u_bw: \", u_bw.shape, u_bw.min(), u_bw.max())\n",
    "        \n",
    "        b_bi = torch.cat((u_fw, u_bw), 1)\n",
    "        #print(\"b_bi: \", b_bi.shape, b_bi.min(), b_bi.max())\n",
    "        out = self.sigmoid(self.fc2(self.dropout(self.relu(self.fc1(b_bi)))))\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "0bbfd9b1-bdd7-4ac2-a20e-4d230da5ae20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "419551"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bitenet_a = BiteNet_ablation()\n",
    "count_para = sum(p.numel() for p in bitenet_a.parameters() if p.requires_grad)\n",
    "count_para"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "91afadcc-6d9c-486e-93cb-a98e0d3b8b34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Train Score: 0.2287, 0.0000, Test Score: 0.1945, 0.0000\n",
      "Epoch: 002, Train Score: 0.2399, 0.0000, Test Score: 0.1926, 0.0000\n",
      "Epoch: 003, Train Score: 0.3330, 0.0000, Test Score: 0.2674, 0.0000\n",
      "Epoch: 004, Train Score: 0.3613, 0.0000, Test Score: 0.2709, 0.0000\n",
      "Epoch: 005, Train Score: 0.3995, 0.0000, Test Score: 0.2678, 0.0000\n",
      "Epoch: 006, Train Score: 0.4286, 0.0000, Test Score: 0.2939, 0.0000\n",
      "Epoch: 007, Train Score: 0.3969, 0.0000, Test Score: 0.2542, 0.0000\n",
      "Epoch: 008, Train Score: 0.4413, 0.0000, Test Score: 0.2623, 0.0000\n",
      "Epoch: 009, Train Score: 0.4706, 0.0000, Test Score: 0.2589, 0.0000\n",
      "Epoch: 010, Train Score: 0.5014, 0.0000, Test Score: 0.2678, 0.0000\n",
      "round 1, auc 0.2677961594968218\n",
      "Epoch: 001, Train Score: 0.2139, 0.0000, Test Score: 0.1866, 0.0000\n",
      "Epoch: 002, Train Score: 0.2322, 0.0000, Test Score: 0.1904, 0.0000\n",
      "Epoch: 003, Train Score: 0.3676, 0.0000, Test Score: 0.2867, 0.0000\n",
      "Epoch: 004, Train Score: 0.3687, 0.0000, Test Score: 0.2844, 0.0000\n",
      "Epoch: 005, Train Score: 0.3738, 0.0000, Test Score: 0.2874, 0.0000\n",
      "Epoch: 006, Train Score: 0.3972, 0.0000, Test Score: 0.2813, 0.0000\n",
      "Epoch: 007, Train Score: 0.3998, 0.0000, Test Score: 0.2686, 0.0000\n",
      "Epoch: 008, Train Score: 0.4062, 0.0000, Test Score: 0.2863, 0.0000\n",
      "Epoch: 009, Train Score: 0.4117, 0.0000, Test Score: 0.2891, 0.0000\n",
      "Epoch: 010, Train Score: 0.4006, 0.0000, Test Score: 0.2850, 0.0000\n",
      "round 2, auc 0.285009008098285\n",
      "Epoch: 001, Train Score: 0.2149, 0.0000, Test Score: 0.1835, 0.0000\n",
      "Epoch: 002, Train Score: 0.2235, 0.0000, Test Score: 0.1845, 0.0000\n",
      "Epoch: 003, Train Score: 0.3605, 0.0000, Test Score: 0.2781, 0.0000\n",
      "Epoch: 004, Train Score: 0.4147, 0.0000, Test Score: 0.2919, 0.0000\n",
      "Epoch: 005, Train Score: 0.4435, 0.0000, Test Score: 0.2738, 0.0000\n",
      "Epoch: 006, Train Score: 0.4422, 0.0000, Test Score: 0.2901, 0.0000\n",
      "Epoch: 007, Train Score: 0.4783, 0.0000, Test Score: 0.3105, 0.0000\n",
      "Epoch: 008, Train Score: 0.4967, 0.0000, Test Score: 0.2943, 0.0000\n",
      "Epoch: 009, Train Score: 0.5411, 0.0000, Test Score: 0.3127, 0.0000\n",
      "Epoch: 010, Train Score: 0.5691, 0.0000, Test Score: 0.3092, 0.0000\n",
      "round 3, auc 0.3092476779407245\n",
      "Epoch: 001, Train Score: 0.2429, 0.0000, Test Score: 0.1977, 0.0000\n",
      "Epoch: 002, Train Score: 0.3814, 0.0000, Test Score: 0.2830, 0.0000\n",
      "Epoch: 003, Train Score: 0.4013, 0.0000, Test Score: 0.2883, 0.0000\n",
      "Epoch: 004, Train Score: 0.4217, 0.0000, Test Score: 0.2861, 0.0000\n",
      "Epoch: 005, Train Score: 0.4275, 0.0000, Test Score: 0.3051, 0.0000\n",
      "Epoch: 006, Train Score: 0.4384, 0.0000, Test Score: 0.3001, 0.0000\n",
      "Epoch: 007, Train Score: 0.4798, 0.0000, Test Score: 0.2691, 0.0000\n",
      "Epoch: 008, Train Score: 0.5037, 0.0000, Test Score: 0.2655, 0.0000\n",
      "Epoch: 009, Train Score: 0.5259, 0.0000, Test Score: 0.2850, 0.0000\n",
      "Epoch: 010, Train Score: 0.5118, 0.0000, Test Score: 0.2850, 0.0000\n",
      "round 4, auc 0.2849645840608782\n",
      "Epoch: 001, Train Score: 0.2187, 0.0000, Test Score: 0.1837, 0.0000\n",
      "Epoch: 002, Train Score: 0.3881, 0.0000, Test Score: 0.2798, 0.0000\n",
      "Epoch: 003, Train Score: 0.3751, 0.0000, Test Score: 0.2688, 0.0000\n",
      "Epoch: 004, Train Score: 0.3944, 0.0000, Test Score: 0.2837, 0.0000\n",
      "Epoch: 005, Train Score: 0.4370, 0.0000, Test Score: 0.2877, 0.0000\n",
      "Epoch: 006, Train Score: 0.4845, 0.0000, Test Score: 0.2870, 0.0000\n",
      "Epoch: 007, Train Score: 0.4962, 0.0000, Test Score: 0.2920, 0.0000\n",
      "Epoch: 008, Train Score: 0.5107, 0.0000, Test Score: 0.3154, 0.0000\n",
      "Epoch: 009, Train Score: 0.5668, 0.0000, Test Score: 0.3077, 0.0000\n",
      "Epoch: 010, Train Score: 0.5958, 0.0000, Test Score: 0.3039, 0.0000\n",
      "round 5, auc 0.3038844478732963\n",
      "Epoch: 001, Train Score: 0.2138, 0.0000, Test Score: 0.1818, 0.0000\n",
      "Epoch: 002, Train Score: 0.2303, 0.0000, Test Score: 0.1881, 0.0000\n",
      "Epoch: 003, Train Score: 0.3501, 0.0000, Test Score: 0.2931, 0.0000\n",
      "Epoch: 004, Train Score: 0.3629, 0.0000, Test Score: 0.2928, 0.0000\n",
      "Epoch: 005, Train Score: 0.3868, 0.0000, Test Score: 0.2953, 0.0000\n",
      "Epoch: 006, Train Score: 0.4351, 0.0000, Test Score: 0.2873, 0.0000\n",
      "Epoch: 007, Train Score: 0.4534, 0.0000, Test Score: 0.3111, 0.0000\n",
      "Epoch: 008, Train Score: 0.4535, 0.0000, Test Score: 0.3001, 0.0000\n",
      "Epoch: 009, Train Score: 0.4275, 0.0000, Test Score: 0.2828, 0.0000\n",
      "Epoch: 010, Train Score: 0.5059, 0.0000, Test Score: 0.2875, 0.0000\n",
      "round 6, auc 0.28747064087844276\n",
      "Epoch: 001, Train Score: 0.2141, 0.0000, Test Score: 0.1805, 0.0000\n",
      "Epoch: 002, Train Score: 0.2278, 0.0000, Test Score: 0.1848, 0.0000\n",
      "Epoch: 003, Train Score: 0.3159, 0.0000, Test Score: 0.2664, 0.0000\n",
      "Epoch: 004, Train Score: 0.3426, 0.0000, Test Score: 0.2791, 0.0000\n",
      "Epoch: 005, Train Score: 0.3895, 0.0000, Test Score: 0.2642, 0.0000\n",
      "Epoch: 006, Train Score: 0.3985, 0.0000, Test Score: 0.2732, 0.0000\n",
      "Epoch: 007, Train Score: 0.3637, 0.0000, Test Score: 0.2577, 0.0000\n",
      "Epoch: 008, Train Score: 0.4353, 0.0000, Test Score: 0.2827, 0.0000\n",
      "Epoch: 009, Train Score: 0.4724, 0.0000, Test Score: 0.3036, 0.0000\n",
      "Epoch: 010, Train Score: 0.4676, 0.0000, Test Score: 0.2966, 0.0000\n",
      "round 7, auc 0.2965593322764252\n",
      "Epoch: 001, Train Score: 0.2172, 0.0000, Test Score: 0.1828, 0.0000\n",
      "Epoch: 002, Train Score: 0.2635, 0.0000, Test Score: 0.2038, 0.0000\n",
      "Epoch: 003, Train Score: 0.3871, 0.0000, Test Score: 0.2866, 0.0000\n",
      "Epoch: 004, Train Score: 0.4398, 0.0000, Test Score: 0.2746, 0.0000\n",
      "Epoch: 005, Train Score: 0.4505, 0.0000, Test Score: 0.2690, 0.0000\n",
      "Epoch: 006, Train Score: 0.4624, 0.0000, Test Score: 0.2816, 0.0000\n",
      "Epoch: 007, Train Score: 0.5125, 0.0000, Test Score: 0.2801, 0.0000\n",
      "Epoch: 008, Train Score: 0.5245, 0.0000, Test Score: 0.2651, 0.0000\n",
      "Epoch: 009, Train Score: 0.5248, 0.0000, Test Score: 0.2659, 0.0000\n",
      "Epoch: 010, Train Score: 0.5686, 0.0000, Test Score: 0.2735, 0.0000\n",
      "round 8, auc 0.27349199146791914\n",
      "Epoch: 001, Train Score: 0.2312, 0.0000, Test Score: 0.1928, 0.0000\n",
      "Epoch: 002, Train Score: 0.2316, 0.0000, Test Score: 0.1878, 0.0000\n",
      "Epoch: 003, Train Score: 0.2575, 0.0000, Test Score: 0.1996, 0.0000\n",
      "Epoch: 004, Train Score: 0.2642, 0.0000, Test Score: 0.1897, 0.0000\n",
      "Epoch: 005, Train Score: 0.2903, 0.0000, Test Score: 0.1969, 0.0000\n",
      "Epoch: 006, Train Score: 0.2885, 0.0000, Test Score: 0.1919, 0.0000\n",
      "Epoch: 007, Train Score: 0.2871, 0.0000, Test Score: 0.1926, 0.0000\n",
      "Epoch: 008, Train Score: 0.3003, 0.0000, Test Score: 0.1989, 0.0000\n",
      "Epoch: 009, Train Score: 0.3604, 0.0000, Test Score: 0.1902, 0.0000\n",
      "Epoch: 010, Train Score: 0.4404, 0.0000, Test Score: 0.2322, 0.0000\n",
      "round 9, auc 0.23219563007522698\n",
      "Epoch: 001, Train Score: 0.2173, 0.0000, Test Score: 0.1815, 0.0000\n",
      "Epoch: 002, Train Score: 0.2210, 0.0000, Test Score: 0.1909, 0.0000\n",
      "Epoch: 003, Train Score: 0.2180, 0.0000, Test Score: 0.1830, 0.0000\n",
      "Epoch: 004, Train Score: 0.2241, 0.0000, Test Score: 0.1832, 0.0000\n",
      "Epoch: 005, Train Score: 0.2324, 0.0000, Test Score: 0.1938, 0.0000\n",
      "Epoch: 006, Train Score: 0.2246, 0.0000, Test Score: 0.1875, 0.0000\n",
      "Epoch: 007, Train Score: 0.2256, 0.0000, Test Score: 0.1708, 0.0000\n",
      "Epoch: 008, Train Score: 0.3012, 0.0000, Test Score: 0.2386, 0.0000\n",
      "Epoch: 009, Train Score: 0.3375, 0.0000, Test Score: 0.2414, 0.0000\n",
      "Epoch: 010, Train Score: 0.3365, 0.0000, Test Score: 0.2575, 0.0000\n",
      "round 10, auc 0.2574738878357966\n",
      "1855.7014272212982\n",
      "mean: 0.27980933600038166, std: 0.021884379397987142\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(bitenet_a.parameters(), lr = 0.001)\n",
    "criterion = torch.nn.BCELoss()\n",
    "\n",
    "def bitenet_a_train(train_loader):\n",
    "    bitenet_a.train()\n",
    "    for data in train_loader:  # Iterate in batches over the training dataset.\n",
    "        x,t,y = data\n",
    "        pred_y = bitenet_a(x, t)\n",
    "        #print(pred_y.shape, pred_y.min(), pred_y.max())\n",
    "        loss = criterion(pred_y, y.float())\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "def bitenet_a_test(loader):\n",
    "    bitenet_a.eval()\n",
    "    pred = []\n",
    "    y_true = []\n",
    "    for data in loader:  # Iterate in batches over the training/test dataset.\n",
    "        x,t,y = data\n",
    "        out = bitenet_a(x, t)\n",
    "        pred +=  out.squeeze().tolist() \n",
    "        y_true += y.squeeze().tolist()\n",
    "    precision, recall, thresholds = precision_recall_curve(y_true, pred)\n",
    "    auc_score = auc(recall, precision)\n",
    "    y_pred = [p>0.5 for p in pred]\n",
    "    #p_score = precision_score(y_true, y_pred)\n",
    "    p_score = 0\n",
    "    return auc_score, p_score\n",
    " \n",
    "\n",
    "\n",
    "ts = time.time()\n",
    "auc_score = []\n",
    "for times in range(10):\n",
    "    bitenet_a.__init__()\n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer = torch.optim.Adam(bitenet_a.parameters(), lr=0.001)\n",
    "    for epoch in range(10):\n",
    "        bitenet_a_train(train_loader)\n",
    "        bitenet_a_train_acc = bitenet_a_test(train_loader)\n",
    "        bitenet_a_test_acc = bitenet_a_test(test_loader)\n",
    "        print(f'Epoch: {epoch + 1:03d}, Train Score: {bitenet_a_train_acc[0]:.4f}, {bitenet_a_train_acc[1]:.4f}, Test Score: {bitenet_a_test_acc[0]:.4f}, {bitenet_a_test_acc[1]:.4f}')\n",
    "    auc_score.append(bitenet_a_test_acc[0])\n",
    "    print(\"round {}, auc {}\".format(times+1, bitenet_a_test_acc[0]))\n",
    "        \n",
    "te = time.time()\n",
    "print(te-ts)\n",
    "auc_ = np.array(auc_score)\n",
    "print(\"mean: {}, std: {}\".format(np.mean(auc_), np.std(auc_)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0a033d3-80d1-445a-a9a1-37b00359252a",
   "metadata": {},
   "source": [
    "### Score decrease. Shows importance of MasEnc blocks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b97178e-3f0a-4611-8034-3fb76ea4350e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
